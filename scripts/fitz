#!/usr/bin/env python
"""
Main execution script for fMRI analysis in the ecosystem.

"""
import os
import sys
import argparse
from nipype import Node, SelectFiles, DataSink  # , IdentityInterface
import fitz
from fitz import tools
import os.path as op


def main(arglist):
    """Main function for workflow setup and execution."""
    args = parse_args(arglist)

    # Get and process specific information
    project = fitz.gather_project_info()
    exp = fitz.gather_experiment_info(args.experiment, args.altmodel)

    # Subject is always highest level of parameterization
    subject_list = fitz.determine_subjects(args.subjects)
    subj_source = tools.make_subject_source(subject_list)

    # Get the full correct name for the experiment
    if args.experiment is None:
        exp_name = project["default_exp"]
    else:
        exp_name = args.experiment

    exp_base = exp_name
    if args.altmodel is not None:
        exp_name = "-".join([exp_base, args.altmodel])

    # Set roots of output storage
    project['analysis_dir'] = op.join(project["analysis_dir"], exp_name)
    project['working_dir'] = op.join(project["working_dir"], exp_name)
    # nipype.config.set("execution", "crashdump_dir", project["crash_dir"])
    # nipype.config.set("logging", "filemanip_level", 'DEBUG')
    # nipype.config.enable_debug_mode()
    # nipype.logging.update_logging(nipype.config)

    setup_dirs(project['analysis_dir'], exp_base, exp_name, subject_list)

    if 'preproc' in args.workflows:
        # Possibly execute the workflow, depending on the command line
        import fitz.pipes.workflows.preproc as f_preproc
        preproc = f_preproc.workflow(project, exp, args, subj_source)
        fitz.run_workflow(preproc, "preproc", args)

    if 'onset' in args.workflows:
        onset_workflow(project, exp, args,
                       data_dir, analysis_dir, working_dir, subj_source)

    if 'model' in args.workflows:
        model_workflow(project, exp, args,
                       data_dir, analysis_dir, working_dir, subj_source)


def setup_dirs(analysis_dir, exp_base, exp_name, subject_list):
    """Create symlinks to the preproc directory for altmodels"""
    if not op.exists(analysis_dir):
        os.makedirs(analysis_dir)
    if exp_base != exp_name:
        for subj in subject_list:
            subj_dir = op.join(analysis_dir, subj)
            if not op.exists(subj_dir):
                os.makedirs(subj_dir)
            link_dir = op.join(analysis_dir, subj, "preproc")
            if not op.exists(link_dir):
                preproc_dir = op.join("../..", exp_base, subj, "preproc")
                os.symlink(preproc_dir, link_dir)



def onset_workflow(project, exp, args,
                   data_dir, analysis_dir, working_dir,
                   subj_source):
    # ----------------------------------------------------------------------- #
    # Create Onsets
    # ----------------------------------------------------------------------- #

    # Create SPM.mat onsets files from design file.
    onset, onset_input, onset_output = wf.create_onset_workflow(
        exp_info=exp)
    onset_base = op.join(data_dir, "{subject_id}/design")
    design_file = exp["design_name"] + ".csv"
    onset_templates = dict(
        design_file=op.join(onset_base, design_file),
    )

    onset_source = Node(SelectFiles(onset_templates), "onsets_source")

    onset_inwrap = tools.InputWrapper(onset, subj_source,
                                      onset_source, onset_input)
    onset_inwrap.connect_inputs()

    onset_sink = Node(DataSink(base_directory=analysis_dir), "onset_sink")

    onset_outwrap = tools.OutputWrapper(onset, subj_source,
                                        onset_sink, onset_output)
    onset_outwrap.set_subject_container()
    onset_outwrap.set_mapnode_substitutions(exp["n_runs"])
    onset_outwrap.sink_outputs("onset")

    # Set temporary output locations
    onset.base_dir = working_dir

    # Possibly execute the workflow
    fitz.run_workflow(onset, "onset", args)


def model_workflow(project, exp, args,
                   data_dir, analysis_dir, working_dir,
                   subj_source):
    # ----------------------------------------------------------------------- #
    # Timeseries Model
    # ----------------------------------------------------------------------- #

    # Create a modelfitting workflow and specific nodes as above
    model, model_input, model_output = wf.create_timeseries_model_workflow(
        name="model", exp_info=exp)

    model_base = op.join(analysis_dir, "{subject_id}/preproc/")
    model_templates = dict(
        timeseries=op.join(model_base,
                           'sw*%s*.img' % op.splitext(op.basename(exp["source_template"]))[0]),
        realignment_params=op.join(model_base, "rp*.txt"),
        onset_files=op.join(analysis_dir, "{subject_id}/onset/*run*.mat")
        )

    # if exp["design_name"] is not None:
    #     design_file = exp["design_name"] + "*.mat"
    #     regressor_file = exp["design_name"] + ".csv"
    #     model_templates["design_file"] = op.join(data_dir, "{subject_id}",
    #                                              "design", design_file)
    # if exp["regressor_file"] is not None:
    #     regressor_file = exp["regressor_file"] + ".csv"
    #     model_templates["regressor_file"] = op.join(data_dir, "{subject_id}",
    #                                                 "design", regressor_file)

    model_source = Node(SelectFiles(model_templates), "model_source")

    model_inwrap = tools.InputWrapper(model, subj_source,
                                      model_source, model_input)
    model_inwrap.connect_inputs()

    model_sink = Node(DataSink(base_directory=analysis_dir), "model_sink")

    model_outwrap = tools.OutputWrapper(model, subj_source,
                                        model_sink, model_output)
    model_outwrap.set_subject_container()
    model_outwrap.set_mapnode_substitutions(exp["n_runs"])
    model_outwrap.sink_outputs("model")

    # Set temporary output locations
    model.base_dir = working_dir

    # Possibly execute the workflow
    fitz.run_workflow(model, "model", args)


def parse_args(arglist):
    """Take an arglist and return an argparse Namespace."""
    # parser = tools.parser

    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()
    run_parser = tools.run_parser(subparsers)

    return parser.parse_args(arglist)


if __name__ == '__main__':
    main(sys.argv[1:])
